{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense, Dropout\n",
    "tf.get_logger().setLevel('ERROR')\n",
    "\n",
    "df = pd.read_csv(\"CatalogoChile2000_2022T.csv\")\n",
    "\n",
    "df = df.loc[df['z'] <= 70]\n",
    "df = df.loc[(df['lat'] >= -60)]\n",
    "df = df.loc[(df['long'] >= -90)]\n",
    "\n",
    "df['fecha'] = pd.to_datetime(df[['year', 'month', 'day', 'hour', 'minute', 'second']])\n",
    "df = df.drop(['year', 'month', 'day', 'hour', 'minute', 'second', 'Unnamed: 0', 'X'], axis=1)\n",
    "df['fecha'] = pd.to_datetime(df['fecha'])  # Asegúrate de que la columna de fecha esté en formato datetime\n",
    "\n",
    "df.set_index('fecha', inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_split(data, train_portion):\n",
    "    num_samples = data.shape[0]\n",
    "\n",
    "    train_size = int(num_samples * train_portion)\n",
    "\n",
    "    train_data = data[:train_size]\n",
    "    test_val_data = data[train_size:]\n",
    "\n",
    "    half_test_val_data = len(test_val_data) // 2\n",
    "    test_data = test_val_data[:half_test_val_data]\n",
    "    val_data = test_val_data[half_test_val_data:]\n",
    "    \n",
    "    return train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train data:  (46151, 5)\n",
      "Test data:  (9889, 5)\n",
      "Validation data:  (9890, 5)\n"
     ]
    }
   ],
   "source": [
    "train_rate = 0.7\n",
    "train_data, test_data, val_data  = train_test_split(df, train_rate)\n",
    "print(\"Train data: \", train_data.shape)\n",
    "print(\"Test data: \", test_data.shape)\n",
    "print(\"Validation data: \", val_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_features = train_data[['lat', 'long', 'z', 'magn1']].values\n",
    "test_data_features = test_data[['lat', 'long', 'z', 'magn1']].values\n",
    "val_data_features = val_data[['lat', 'long', 'z', 'magn1']].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    xs, ys = [], []\n",
    "    for i in range(len(data) - seq_length):\n",
    "        x = data[i:i+seq_length]\n",
    "        y = data[i+seq_length, 3]\n",
    "        xs.append(x)\n",
    "        ys.append(y)\n",
    "    return np.array(xs), np.array(ys)\n",
    "\n",
    "SEQ_LENGTH = 21\n",
    "trainX, trainY = create_sequences(train_data_features, SEQ_LENGTH)\n",
    "testX, testY = create_sequences(test_data_features, SEQ_LENGTH)\n",
    "valX, valY = create_sequences(val_data_features, SEQ_LENGTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "def weighted_binary_crossentropy(y_true, y_pred):\n",
    "    y_true = tf.cast(y_true, tf.float32)\n",
    "    # Define los pesos\n",
    "    weight_for_1 = 15.0 ## PESO_PARAMETRO\n",
    "    weight_for_0 = 1.0\n",
    "    \n",
    "    # Calcula la pérdida binaria cruzada básica\n",
    "    bce = K.binary_crossentropy(y_true, y_pred)\n",
    "    \n",
    "    # Crea una máscara para asignar el peso correcto a cada clase\n",
    "    weight_vector = y_true * weight_for_1 + (1.0 - y_true) * weight_for_0\n",
    "    \n",
    "    # Aplica el peso a la pérdida\n",
    "    weighted_bce = weight_vector * bce\n",
    "    \n",
    "    return K.mean(weighted_bce)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def binarize_data(data, threshold):\n",
    "    binarized_data = np.where(data > threshold, 1, 0)\n",
    "    return binarized_data\n",
    "\n",
    "threshold = 4.0 ## THRESHOLD_PARAMETRO\n",
    "binarized_trainY = binarize_data(trainY, threshold)\n",
    "binarized_testY = binarize_data(testY, threshold)\n",
    "binarized_valY = binarize_data(valY, threshold)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46130, 21, 4)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainX.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Definimos el modelo LSTM\n",
    "# model = Sequential([\n",
    "#     LSTM(64, input_shape=(trainX.shape[1], trainX.shape[2]), return_sequences=False),  # Capa LSTM\n",
    "#     Dropout(0.2),  # Regularización para evitar overfitting\n",
    "#     Dense(32, activation='relu'),  # Capa densa intermedia\n",
    "#     Dense(1, activation='sigmoid')  # Capa de salida para clasificación binaria\n",
    "# ])\n",
    "\n",
    "# # Compilamos el modelo\n",
    "# model.compile(optimizer='adam', loss=weighted_binary_crossentropy, metrics=['binary_accuracy'])\n",
    "\n",
    "# # Entrenamos el modelo\n",
    "# history = model.fit(trainX, binarized_trainY, epochs=100, batch_size=16, validation_data=(valX, binarized_valY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainX = train_data.drop(columns=[\"magn1\"])\n",
    "trainY = train_data[\"magn1\"]\n",
    "\n",
    "testX = test_data.drop(columns=[\"magn1\"])\n",
    "testY = test_data[\"magn1\"]\n",
    "\n",
    "valX = val_data.drop(columns=[\"magn1\"])\n",
    "valY = val_data[\"magn1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "2885/2885 [==============================] - 3s 864us/step - loss: 19.9749 - binary_accuracy: 0.3623 - val_loss: 13.5352 - val_binary_accuracy: 0.0663\n",
      "Epoch 2/100\n",
      "2885/2885 [==============================] - 2s 827us/step - loss: 7.4734 - binary_accuracy: 0.3610 - val_loss: 6.9198 - val_binary_accuracy: 0.0663\n",
      "Epoch 3/100\n",
      "2885/2885 [==============================] - 2s 825us/step - loss: 4.2994 - binary_accuracy: 0.3352 - val_loss: 3.3323 - val_binary_accuracy: 0.0663\n",
      "Epoch 4/100\n",
      "2885/2885 [==============================] - 2s 809us/step - loss: 2.5198 - binary_accuracy: 0.3011 - val_loss: 5.0072 - val_binary_accuracy: 0.0663\n",
      "Epoch 5/100\n",
      "2885/2885 [==============================] - 2s 820us/step - loss: 1.8504 - binary_accuracy: 0.1836 - val_loss: 1.7708 - val_binary_accuracy: 0.0663\n",
      "Epoch 6/100\n",
      "2885/2885 [==============================] - 2s 838us/step - loss: 1.7516 - binary_accuracy: 0.1339 - val_loss: 2.0098 - val_binary_accuracy: 0.0663\n",
      "Epoch 7/100\n",
      "2885/2885 [==============================] - 2s 828us/step - loss: 1.7525 - binary_accuracy: 0.1340 - val_loss: 1.4315 - val_binary_accuracy: 0.0663\n",
      "Epoch 8/100\n",
      "2885/2885 [==============================] - 2s 850us/step - loss: 1.7526 - binary_accuracy: 0.1347 - val_loss: 1.7876 - val_binary_accuracy: 0.0663\n",
      "Epoch 9/100\n",
      "2885/2885 [==============================] - 2s 822us/step - loss: 1.7628 - binary_accuracy: 0.1349 - val_loss: 1.4225 - val_binary_accuracy: 0.0663\n",
      "Epoch 10/100\n",
      "2885/2885 [==============================] - 2s 833us/step - loss: 1.7572 - binary_accuracy: 0.1346 - val_loss: 1.4590 - val_binary_accuracy: 0.0663\n",
      "Epoch 11/100\n",
      "2885/2885 [==============================] - 2s 844us/step - loss: 1.7623 - binary_accuracy: 0.1351 - val_loss: 1.4661 - val_binary_accuracy: 0.0663\n",
      "Epoch 12/100\n",
      "2885/2885 [==============================] - 2s 848us/step - loss: 1.7525 - binary_accuracy: 0.1341 - val_loss: 1.4672 - val_binary_accuracy: 0.0663\n",
      "Epoch 13/100\n",
      "2885/2885 [==============================] - 3s 948us/step - loss: 1.7548 - binary_accuracy: 0.1347 - val_loss: 1.4622 - val_binary_accuracy: 0.0663\n",
      "Epoch 14/100\n",
      "2885/2885 [==============================] - 3s 979us/step - loss: 1.7536 - binary_accuracy: 0.1341 - val_loss: 1.4541 - val_binary_accuracy: 0.0663\n",
      "Epoch 15/100\n",
      "2885/2885 [==============================] - 3s 1ms/step - loss: 1.7527 - binary_accuracy: 0.1339 - val_loss: 1.4641 - val_binary_accuracy: 0.0663\n",
      "Epoch 16/100\n",
      "2885/2885 [==============================] - 2s 840us/step - loss: 1.7565 - binary_accuracy: 0.1353 - val_loss: 1.4631 - val_binary_accuracy: 0.0663\n",
      "Epoch 17/100\n",
      "2885/2885 [==============================] - 2s 831us/step - loss: 1.7568 - binary_accuracy: 0.1342 - val_loss: 1.4647 - val_binary_accuracy: 0.0663\n",
      "Epoch 18/100\n",
      "2885/2885 [==============================] - 2s 822us/step - loss: 1.7545 - binary_accuracy: 0.1340 - val_loss: 1.4634 - val_binary_accuracy: 0.0663\n",
      "Epoch 19/100\n",
      "2885/2885 [==============================] - 2s 794us/step - loss: 1.7521 - binary_accuracy: 0.1342 - val_loss: 1.4548 - val_binary_accuracy: 0.0663\n",
      "Epoch 20/100\n",
      "2885/2885 [==============================] - 2s 813us/step - loss: 1.7517 - binary_accuracy: 0.1340 - val_loss: 1.4678 - val_binary_accuracy: 0.0663\n",
      "Epoch 21/100\n",
      "2885/2885 [==============================] - 2s 841us/step - loss: 1.7519 - binary_accuracy: 0.1341 - val_loss: 1.4700 - val_binary_accuracy: 0.0663\n",
      "Epoch 22/100\n",
      "2885/2885 [==============================] - 2s 853us/step - loss: 1.7520 - binary_accuracy: 0.1342 - val_loss: 1.4665 - val_binary_accuracy: 0.0663\n",
      "Epoch 23/100\n",
      "2885/2885 [==============================] - 3s 1ms/step - loss: 1.7521 - binary_accuracy: 0.1340 - val_loss: 1.4723 - val_binary_accuracy: 0.0663\n",
      "Epoch 24/100\n",
      "2885/2885 [==============================] - 2s 844us/step - loss: 1.7533 - binary_accuracy: 0.1341 - val_loss: 1.4609 - val_binary_accuracy: 0.0663\n",
      "Epoch 25/100\n",
      "2885/2885 [==============================] - 2s 861us/step - loss: 1.7519 - binary_accuracy: 0.1340 - val_loss: 1.4662 - val_binary_accuracy: 0.0663\n",
      "Epoch 26/100\n",
      "2885/2885 [==============================] - 3s 870us/step - loss: 1.7537 - binary_accuracy: 0.1341 - val_loss: 1.4641 - val_binary_accuracy: 0.0663\n",
      "Epoch 27/100\n",
      "2885/2885 [==============================] - 2s 833us/step - loss: 1.7510 - binary_accuracy: 0.1341 - val_loss: 1.4609 - val_binary_accuracy: 0.0663\n",
      "Epoch 28/100\n",
      "2885/2885 [==============================] - 2s 855us/step - loss: 1.7532 - binary_accuracy: 0.1341 - val_loss: 1.4675 - val_binary_accuracy: 0.0663\n",
      "Epoch 29/100\n",
      "2885/2885 [==============================] - 2s 843us/step - loss: 1.7515 - binary_accuracy: 0.1340 - val_loss: 1.4593 - val_binary_accuracy: 0.0663\n",
      "Epoch 30/100\n",
      "2885/2885 [==============================] - 2s 849us/step - loss: 1.7521 - binary_accuracy: 0.1340 - val_loss: 1.4671 - val_binary_accuracy: 0.0663\n",
      "Epoch 31/100\n",
      "2885/2885 [==============================] - 2s 820us/step - loss: 1.7507 - binary_accuracy: 0.1342 - val_loss: 1.4733 - val_binary_accuracy: 0.0663\n",
      "Epoch 32/100\n",
      "2885/2885 [==============================] - 2s 820us/step - loss: 1.7535 - binary_accuracy: 0.1342 - val_loss: 1.4598 - val_binary_accuracy: 0.0663\n",
      "Epoch 33/100\n",
      "2885/2885 [==============================] - 2s 828us/step - loss: 1.7514 - binary_accuracy: 0.1340 - val_loss: 1.4653 - val_binary_accuracy: 0.0663\n",
      "Epoch 34/100\n",
      "2885/2885 [==============================] - 2s 821us/step - loss: 1.7558 - binary_accuracy: 0.1343 - val_loss: 1.4629 - val_binary_accuracy: 0.0663\n",
      "Epoch 35/100\n",
      "2885/2885 [==============================] - 2s 808us/step - loss: 1.7511 - binary_accuracy: 0.1341 - val_loss: 1.4618 - val_binary_accuracy: 0.0663\n",
      "Epoch 36/100\n",
      "2885/2885 [==============================] - 2s 802us/step - loss: 1.7512 - binary_accuracy: 0.1340 - val_loss: 1.4666 - val_binary_accuracy: 0.0663\n",
      "Epoch 37/100\n",
      "2885/2885 [==============================] - 2s 816us/step - loss: 1.7517 - binary_accuracy: 0.1341 - val_loss: 1.4665 - val_binary_accuracy: 0.0663\n",
      "Epoch 38/100\n",
      "2885/2885 [==============================] - 2s 825us/step - loss: 1.7519 - binary_accuracy: 0.1341 - val_loss: 1.4643 - val_binary_accuracy: 0.0663\n",
      "Epoch 39/100\n",
      "2885/2885 [==============================] - 2s 842us/step - loss: 1.7516 - binary_accuracy: 0.1339 - val_loss: 1.4661 - val_binary_accuracy: 0.0663\n",
      "Epoch 40/100\n",
      "2885/2885 [==============================] - 2s 819us/step - loss: 1.7507 - binary_accuracy: 0.1341 - val_loss: 1.4656 - val_binary_accuracy: 0.0663\n",
      "Epoch 41/100\n",
      "2885/2885 [==============================] - 2s 805us/step - loss: 1.7507 - binary_accuracy: 0.1340 - val_loss: 1.4734 - val_binary_accuracy: 0.0663\n",
      "Epoch 42/100\n",
      "2885/2885 [==============================] - 2s 831us/step - loss: 1.7521 - binary_accuracy: 0.1341 - val_loss: 1.4664 - val_binary_accuracy: 0.0663\n",
      "Epoch 43/100\n",
      "2885/2885 [==============================] - 2s 834us/step - loss: 1.7505 - binary_accuracy: 0.1340 - val_loss: 1.4554 - val_binary_accuracy: 0.0663\n",
      "Epoch 44/100\n",
      "2885/2885 [==============================] - 2s 831us/step - loss: 1.7521 - binary_accuracy: 0.1341 - val_loss: 1.4735 - val_binary_accuracy: 0.0663\n",
      "Epoch 45/100\n",
      "2885/2885 [==============================] - 2s 809us/step - loss: 1.7549 - binary_accuracy: 0.1342 - val_loss: 1.4612 - val_binary_accuracy: 0.0663\n",
      "Epoch 46/100\n",
      "2885/2885 [==============================] - 2s 821us/step - loss: 1.7508 - binary_accuracy: 0.1342 - val_loss: 1.4613 - val_binary_accuracy: 0.0663\n",
      "Epoch 47/100\n",
      "2885/2885 [==============================] - 2s 837us/step - loss: 1.7513 - binary_accuracy: 0.1343 - val_loss: 1.4652 - val_binary_accuracy: 0.0663\n",
      "Epoch 48/100\n",
      "2885/2885 [==============================] - 2s 832us/step - loss: 1.7546 - binary_accuracy: 0.1340 - val_loss: 1.4656 - val_binary_accuracy: 0.0663\n",
      "Epoch 49/100\n",
      "2885/2885 [==============================] - 2s 814us/step - loss: 1.7506 - binary_accuracy: 0.1342 - val_loss: 1.4638 - val_binary_accuracy: 0.0663\n",
      "Epoch 50/100\n",
      "2885/2885 [==============================] - 2s 799us/step - loss: 1.7521 - binary_accuracy: 0.1341 - val_loss: 1.4631 - val_binary_accuracy: 0.0663\n",
      "Epoch 51/100\n",
      "2885/2885 [==============================] - 2s 817us/step - loss: 1.7510 - binary_accuracy: 0.1338 - val_loss: 1.4731 - val_binary_accuracy: 0.0663\n",
      "Epoch 52/100\n",
      "2885/2885 [==============================] - 2s 817us/step - loss: 1.7501 - binary_accuracy: 0.1340 - val_loss: 1.4594 - val_binary_accuracy: 0.0663\n",
      "Epoch 53/100\n",
      "2885/2885 [==============================] - 2s 838us/step - loss: 1.7522 - binary_accuracy: 0.1344 - val_loss: 1.4690 - val_binary_accuracy: 0.0663\n",
      "Epoch 54/100\n",
      "2885/2885 [==============================] - 2s 839us/step - loss: 1.7506 - binary_accuracy: 0.1340 - val_loss: 1.4627 - val_binary_accuracy: 0.0663\n",
      "Epoch 55/100\n",
      "2885/2885 [==============================] - 2s 818us/step - loss: 1.7527 - binary_accuracy: 0.1340 - val_loss: 1.4657 - val_binary_accuracy: 0.0663\n",
      "Epoch 56/100\n",
      "2885/2885 [==============================] - 2s 825us/step - loss: 1.7543 - binary_accuracy: 0.1343 - val_loss: 1.4613 - val_binary_accuracy: 0.0663\n",
      "Epoch 57/100\n",
      "2885/2885 [==============================] - 2s 806us/step - loss: 1.7530 - binary_accuracy: 0.1342 - val_loss: 1.4670 - val_binary_accuracy: 0.0663\n",
      "Epoch 58/100\n",
      "2885/2885 [==============================] - 2s 810us/step - loss: 1.7526 - binary_accuracy: 0.1342 - val_loss: 1.4600 - val_binary_accuracy: 0.0663\n",
      "Epoch 59/100\n",
      "2885/2885 [==============================] - 2s 809us/step - loss: 1.7506 - binary_accuracy: 0.1342 - val_loss: 1.4643 - val_binary_accuracy: 0.0663\n",
      "Epoch 60/100\n",
      "2885/2885 [==============================] - 2s 813us/step - loss: 1.7523 - binary_accuracy: 0.1340 - val_loss: 1.4569 - val_binary_accuracy: 0.0663\n",
      "Epoch 61/100\n",
      "2885/2885 [==============================] - 2s 796us/step - loss: 1.7505 - binary_accuracy: 0.1340 - val_loss: 1.4666 - val_binary_accuracy: 0.0663\n",
      "Epoch 62/100\n",
      "2885/2885 [==============================] - 2s 856us/step - loss: 1.7518 - binary_accuracy: 0.1344 - val_loss: 1.4587 - val_binary_accuracy: 0.0663\n",
      "Epoch 63/100\n",
      "2885/2885 [==============================] - 2s 833us/step - loss: 1.7505 - binary_accuracy: 0.1346 - val_loss: 1.4759 - val_binary_accuracy: 0.0663\n",
      "Epoch 64/100\n",
      "2885/2885 [==============================] - 3s 893us/step - loss: 1.7555 - binary_accuracy: 0.1351 - val_loss: 1.4643 - val_binary_accuracy: 0.0663\n",
      "Epoch 65/100\n",
      "2885/2885 [==============================] - 2s 863us/step - loss: 1.7504 - binary_accuracy: 0.1343 - val_loss: 1.4640 - val_binary_accuracy: 0.0663\n",
      "Epoch 66/100\n",
      "2885/2885 [==============================] - 3s 872us/step - loss: 1.7552 - binary_accuracy: 0.1341 - val_loss: 1.4664 - val_binary_accuracy: 0.0663\n",
      "Epoch 67/100\n",
      "2885/2885 [==============================] - 2s 844us/step - loss: 1.7516 - binary_accuracy: 0.1342 - val_loss: 1.4703 - val_binary_accuracy: 0.0663\n",
      "Epoch 68/100\n",
      "2885/2885 [==============================] - 3s 883us/step - loss: 1.7502 - binary_accuracy: 0.1343 - val_loss: 1.4712 - val_binary_accuracy: 0.0663\n",
      "Epoch 69/100\n",
      "2885/2885 [==============================] - 2s 839us/step - loss: 1.7531 - binary_accuracy: 0.1340 - val_loss: 1.4667 - val_binary_accuracy: 0.0663\n",
      "Epoch 70/100\n",
      "2885/2885 [==============================] - 2s 823us/step - loss: 1.7507 - binary_accuracy: 0.1340 - val_loss: 1.4636 - val_binary_accuracy: 0.0663\n",
      "Epoch 71/100\n",
      "2885/2885 [==============================] - 2s 818us/step - loss: 1.7505 - binary_accuracy: 0.1343 - val_loss: 1.4695 - val_binary_accuracy: 0.0663\n",
      "Epoch 72/100\n",
      "2885/2885 [==============================] - 2s 837us/step - loss: 1.7596 - binary_accuracy: 0.1347 - val_loss: 1.4719 - val_binary_accuracy: 0.0663\n",
      "Epoch 73/100\n",
      "2885/2885 [==============================] - 3s 869us/step - loss: 1.7518 - binary_accuracy: 0.1342 - val_loss: 1.4653 - val_binary_accuracy: 0.0663\n",
      "Epoch 74/100\n",
      "2885/2885 [==============================] - 3s 879us/step - loss: 1.7522 - binary_accuracy: 0.1353 - val_loss: 1.4645 - val_binary_accuracy: 0.0663\n",
      "Epoch 75/100\n",
      "2885/2885 [==============================] - 2s 848us/step - loss: 1.7542 - binary_accuracy: 0.1355 - val_loss: 1.4599 - val_binary_accuracy: 0.0663\n",
      "Epoch 76/100\n",
      "2885/2885 [==============================] - 3s 925us/step - loss: 1.7502 - binary_accuracy: 0.1342 - val_loss: 1.4731 - val_binary_accuracy: 0.0663\n",
      "Epoch 77/100\n",
      "2885/2885 [==============================] - 3s 1ms/step - loss: 1.7510 - binary_accuracy: 0.1340 - val_loss: 1.4716 - val_binary_accuracy: 0.0663\n",
      "Epoch 78/100\n",
      "2885/2885 [==============================] - 3s 1ms/step - loss: 1.7509 - binary_accuracy: 0.1341 - val_loss: 1.4645 - val_binary_accuracy: 0.0663\n",
      "Epoch 79/100\n",
      "2885/2885 [==============================] - 3s 924us/step - loss: 1.7567 - binary_accuracy: 0.1349 - val_loss: 1.4552 - val_binary_accuracy: 0.0663\n",
      "Epoch 80/100\n",
      "2885/2885 [==============================] - 3s 893us/step - loss: 1.7509 - binary_accuracy: 0.1346 - val_loss: 1.4611 - val_binary_accuracy: 0.0663\n",
      "Epoch 81/100\n",
      "2885/2885 [==============================] - 3s 894us/step - loss: 1.7570 - binary_accuracy: 0.1356 - val_loss: 1.4596 - val_binary_accuracy: 0.0663\n",
      "Epoch 82/100\n",
      "2885/2885 [==============================] - 3s 915us/step - loss: 1.7492 - binary_accuracy: 0.1341 - val_loss: 1.4706 - val_binary_accuracy: 0.0663\n",
      "Epoch 83/100\n",
      "2885/2885 [==============================] - 3s 965us/step - loss: 1.7517 - binary_accuracy: 0.1345 - val_loss: 1.4562 - val_binary_accuracy: 0.0663\n",
      "Epoch 84/100\n",
      "2885/2885 [==============================] - 3s 930us/step - loss: 1.7504 - binary_accuracy: 0.1340 - val_loss: 1.4690 - val_binary_accuracy: 0.0663\n",
      "Epoch 85/100\n",
      "2885/2885 [==============================] - 3s 905us/step - loss: 1.7498 - binary_accuracy: 0.1341 - val_loss: 1.4642 - val_binary_accuracy: 0.0663\n",
      "Epoch 86/100\n",
      "2885/2885 [==============================] - 2s 862us/step - loss: 1.7497 - binary_accuracy: 0.1341 - val_loss: 1.4630 - val_binary_accuracy: 0.0663\n",
      "Epoch 87/100\n",
      "2885/2885 [==============================] - 3s 1ms/step - loss: 1.7493 - binary_accuracy: 0.1342 - val_loss: 1.4582 - val_binary_accuracy: 0.0663\n",
      "Epoch 88/100\n",
      "2885/2885 [==============================] - 3s 930us/step - loss: 1.7516 - binary_accuracy: 0.1343 - val_loss: 1.4629 - val_binary_accuracy: 0.0663\n",
      "Epoch 89/100\n",
      "2885/2885 [==============================] - 3s 877us/step - loss: 1.7492 - binary_accuracy: 0.1342 - val_loss: 1.4633 - val_binary_accuracy: 0.0663\n",
      "Epoch 90/100\n",
      "2885/2885 [==============================] - 3s 933us/step - loss: 1.7485 - binary_accuracy: 0.1341 - val_loss: 1.4693 - val_binary_accuracy: 0.0663\n",
      "Epoch 91/100\n",
      "2885/2885 [==============================] - 3s 1ms/step - loss: 1.7474 - binary_accuracy: 0.1343 - val_loss: 1.4567 - val_binary_accuracy: 0.0663\n",
      "Epoch 92/100\n",
      "2885/2885 [==============================] - 3s 934us/step - loss: 1.7480 - binary_accuracy: 0.1344 - val_loss: 1.4625 - val_binary_accuracy: 0.0663\n",
      "Epoch 93/100\n",
      "2885/2885 [==============================] - 3s 971us/step - loss: 1.7472 - binary_accuracy: 0.1340 - val_loss: 1.4606 - val_binary_accuracy: 0.0663\n",
      "Epoch 94/100\n",
      "2885/2885 [==============================] - 3s 930us/step - loss: 1.7478 - binary_accuracy: 0.1346 - val_loss: 1.4570 - val_binary_accuracy: 0.0663\n",
      "Epoch 95/100\n",
      "2885/2885 [==============================] - 3s 968us/step - loss: 1.7469 - binary_accuracy: 0.1342 - val_loss: 1.4656 - val_binary_accuracy: 0.0663\n",
      "Epoch 96/100\n",
      "2885/2885 [==============================] - 3s 949us/step - loss: 1.7498 - binary_accuracy: 0.1345 - val_loss: 1.4618 - val_binary_accuracy: 0.0663\n",
      "Epoch 97/100\n",
      "2885/2885 [==============================] - 3s 963us/step - loss: 1.7471 - binary_accuracy: 0.1343 - val_loss: 1.4587 - val_binary_accuracy: 0.0663\n",
      "Epoch 98/100\n",
      "2885/2885 [==============================] - 3s 1ms/step - loss: 1.7453 - binary_accuracy: 0.1342 - val_loss: 1.4651 - val_binary_accuracy: 0.0663\n",
      "Epoch 99/100\n",
      "2885/2885 [==============================] - 3s 1ms/step - loss: 1.7582 - binary_accuracy: 0.1364 - val_loss: 1.4597 - val_binary_accuracy: 0.0663\n",
      "Epoch 100/100\n",
      "2885/2885 [==============================] - 3s 990us/step - loss: 1.7459 - binary_accuracy: 0.1345 - val_loss: 1.4688 - val_binary_accuracy: 0.0663\n"
     ]
    }
   ],
   "source": [
    "# Crear el modelo\n",
    "model = Sequential()\n",
    "# Capa de entrada y primera capa oculta\n",
    "model.add(Dense(units=128, activation='relu', input_dim=4))\n",
    "# Segunda capa oculta\n",
    "model.add(Dense(units=64, activation='relu'))\n",
    "# Capa de salida\n",
    "model.add(Dense(units=1, activation='sigmoid'))  # Para clasificación binaria\n",
    "\n",
    "# Compilar el modelo\n",
    "model.compile(optimizer='adam', loss=weighted_binary_crossentropy, metrics=['binary_accuracy'])\n",
    "\n",
    "history = model.fit(trainX, binarized_trainY, epochs=100, batch_size=16, validation_data=(valX, binarized_valY))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loss:  1.7459062337875366 \n",
      "Test loss: 1.4688032865524292\n"
     ]
    }
   ],
   "source": [
    "print(\n",
    "    \"Train loss: \",\n",
    "    history.history[\"loss\"][-1],\n",
    "    \"\\nTest loss:\",\n",
    "    history.history[\"val_loss\"][-1],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "310/310 [==============================] - 0s 701us/step\n"
     ]
    }
   ],
   "source": [
    "yhat = model.predict(testX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "yhat_bin = (yhat > 0.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.0716\n",
      "Precision: 0.0716\n",
      "Recall: 1.0\n",
      "F1-Score: 0.1336\n",
      "Matriz de Confusión:\n",
      "[[   0 9181]\n",
      " [   0  708]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n",
    "\n",
    "yhat_bin = (yhat > 0.5).astype(int)\n",
    "yhat_bin_flatten = yhat_bin.ravel()\n",
    "binarized_valY_flatten = binarized_testY.ravel()\n",
    "\n",
    "accuracy = accuracy_score(binarized_valY_flatten, yhat_bin_flatten)\n",
    "precision = precision_score(binarized_valY_flatten, yhat_bin_flatten)\n",
    "recall = recall_score(binarized_valY_flatten, yhat_bin_flatten)\n",
    "f1 = f1_score(binarized_valY_flatten, yhat_bin_flatten)\n",
    "conf_matrix = confusion_matrix(binarized_valY_flatten, yhat_bin_flatten)\n",
    "\n",
    "print(f'Accuracy: {round(accuracy, 4)}')\n",
    "print(f'Precision: {round(precision, 4)}')\n",
    "print(f'Recall: {round(recall, 4)}')\n",
    "print(f'F1-Score: {round(f1, 4)}')\n",
    "print(f'Matriz de Confusión:\\n{conf_matrix}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
